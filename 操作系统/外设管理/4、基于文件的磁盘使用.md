# 基于文件的磁盘使用
## L4：引出文件

抽象到现在，用户通过盘块号来调用 bread 函数，就可以读写磁盘了

* 直接通过盘块号来使用磁盘，即使对那些熟知磁盘块的程序员也很不方便，例如要将一块很大的内容写到多个磁盘块中，此时程序员需要自己记住这块内容中的哪一段被写到哪一个盘块中，因为将来要根据这个对应关系再从磁盘的相应块中取出这些数据内容。
* 为了让磁盘上的数据访问更符合人的习惯，操作系统引出了磁盘使用的第四层抽象---文件，**文件是一个连续的字符流**。
  * 不管是什么数据，也不管这个数据内容有多大，我们都将其看成是一个字符流。



操作系统的这一层抽象就是要将磁盘块抽象为一个字符流

* （1）用户看到并访问的是一个文件，是一个字符流，和磁盘块没有任何关系，比如用户请求“要读入文件 test.c 中 200 —211 的 12 个字符”。
* （2）从磁盘物理设备出发，磁盘中只有磁盘块，所以字符流最终还是要存放在磁盘块上，比如将文件 test.c 中 200 —211 这 12 个字符存放到磁盘块 789 上。
* （3）操作系统要将字符流读写映射为对磁盘块的读写，对于上面给出的 test.c 实例，通过处理一个完成字符流到磁盘块映射的数据结构，操作系统知道处理字符流位置200 —211 就是去处理磁盘块 789。再得到 789 这个磁盘块号以后，操作系统直接调用 bread(789) 去真正读磁盘即可。



显然，实现文件抽象的关键就在于能根据字符流位置找到对应的盘块号，即字符流和盘块号之间的映射关系。

* 那么，给定一个文件，到底如何将其字符流存放在磁盘块上呢？



连续存放

![在这里插入图片描述](https://img-blog.csdnimg.cn/20210121005520616.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzkzNDYwNw==,size_16,color_FFFFFF,t_70)


* 这个存放/映射结构通常被称为是顺序存储结构 
* 操作系统只需要存放”起始块号“和”长度“这两个信息就能描述那个映射关系，就可以很容易地算出字符流位置对应的磁盘块号
  * 完成这个映射核心信息是“文件名、起始块号、文件长度”，这个信息可以用一个核心数据结构 文件控制块（File Control Block，简称 FCB，即 innode ，主要是根据逻辑盘块号索引物理盘块）来组织和保存。
  * 所以，创建文件时，操作系统会将文件对应的字符流依次存放在盘块号连续的多个磁盘块上，然后将存放该字符流的第一个盘块号填写在该文件的 FCB上。
  * 在用户要访问字符流位置 pos 时，操作系统会从该文件的 FCB 上取出起始块号 start_blocknr，然后通过公式$blocknr = start\_blocknr + pos/BLOCK\_SIZE$，计算出该字符流位置所在的磁盘块块号，剩下的工作就是用盘块号来读写磁盘了。
* 优缺点
  * 优点：访问任何一个字符流位置都能根据上面给出的公式快速计算出对应磁盘块号。
  * 缺点：如果要对文件进行改写，比如要在文件的某个中间位置添加一些字符。为保证添加以后的字符流在磁盘上仍连续存放，需要将这个中间位置以后的磁盘块内容全部往后挪动，即要逐个将这些后面的磁盘块读入并写出到下一个磁盘块上，这需要大量的磁盘读写操作，非常费时。
  * 另外，如果要对某个文件进行追加，有可能追加以后的文件会覆盖后面的文件。
* 因此对于顺序存储结构文件，静态读操作很高效，但文件的修改、追加、删除等动态操作很低效。



链式存储结构

![在这里插入图片描述](https://img-blog.csdnimg.cn/20210121005535574.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzkzNDYwNw==,size_16,color_FFFFFF,t_70)


* 实现方案也很简单：文件字符流存放的磁盘块不需要连续，只要每个磁盘块中存放下一个字符流片段所在的盘块号即可。这样就会形成一个“链” 式结构

  * 对于链式存储结构而言，操作系统在 FCB 中需要存放的主要映射信息仍然是第一个磁盘块的盘块号
  * 利用这个信息可以找到文件的第一个磁盘块，再利用每个磁盘块中存放的下一个盘块号，可以找到第二个磁盘块，依次类推，可以计算出文件中任何字符流位置所对应的盘块号。
* 显然链式存储结构下的文件读效率很低
* 例如想找到第 3 个逻辑盘块对应的物理盘块号，需要读入前 2 个盘块。
* 但链式存储结构的文件在动态修改时不需要进行大量的磁盘块移动，只要修改前一个磁盘块使其指向正确的下一个盘块号即可。
* 顺序存储结构文件的读操作效率高，链式存储结构文件的修改操作效率高，两种存储结构各有优缺点。



索引存储结构

![在这里插入图片描述](https://img-blog.csdnimg.cn/2021012100555220.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzkzNDYwNw==,size_16,color_FFFFFF,t_70)


* 一个通用操作系统中，既有文件读操作也有文件写操作，有没有一种可以折中的方案使得文件读写操作的效率都较高？
  * 索引存储结构是一个对文件读操作和文件写操作都支持较好的文件映射方案。所以很多实际操作系统都使用这样的索引存储结构，如 UNIX、Linux 等操作系统。
* 索引存储结构下的文件映射方案也容易理解，文件字符流被分割成多个逻辑块，在物理磁盘上寻找一些空闲物理盘块（无需连续）将这些逻辑块的内容存放进去，再找一个磁盘块作为索引块，其中按序存放各个逻辑块对应的物理磁盘块号
* 索引存储结构针对文件读操作和文件写操作都具有不错的性能。
  * 读取（例如想读取文件内部逻辑上第 3 个块）：无需像链式存储结构那样读入前两个逻辑块。当然也不能像顺序存储结构那样直接通过 FCB 中的内容来算出第 3 个逻辑块对应的物理盘块号，需要读入索引块以后才可以查到这个映射关系。
  * 写入：索引存储结构下字符流不用在物理磁盘上连续存放，所以文件的动态修改也不困难，无需像顺序存储结构那样大量移动物理盘块。



一些细节问题：

* 一个很小的文件，比如只有一个磁盘块大小的文件，还要引入索引块吗？

* 当一个文件很大时，存放字符流的磁盘块号数量太多，多到一个索引块（也是一个磁盘块）容纳不下时该怎么办？



为解决上述问题，实际操作系统会使用的索引存储结构（innode）如下

![在这里插入图片描述](https://img-blog.csdnimg.cn/20210121005609807.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzkzNDYwNw==,size_16,color_FFFFFF,t_70)


* 索引节点（就是文件 FCB 的一部分，因为是索引结构，所以通常被称作索引节点，indexnode，简称 inode）中存放了**直接数据块的块号、索引块块号、以及间接索引块块号**三个部分（索引项的值就是逻辑块号，即文件中第几个块）。
  * 直接数据块直接指向文件内容（即直接指向数据块），字符流中的前 6 个逻辑块对应的磁盘块号可以用 inode 中的直接块信息直接获得。
  * 利用 innode 里的一阶索引块号可以读出索引块，然后根据索引块中存放的物理盘块号可以找到文件的内容，由于只用读入一次索引块，所以被称为是一阶索引
  * 间接索引，首先要读入间接索引块，其中存放的是下一阶索引的索引块号，下一阶索引块中存放的才是对应于逻辑块的物理盘块号，这是二阶索引。当然我们还可以设计三阶索引，四阶索引

* 工作效果：
  * （1）首先是索引存储结构，所以能较好地支持文件读操作和写操作。
  * （2）如果文件比较小，比如小于 6 个盘块，可以利用 inode（在读写文件时这个数据结构通常是已经读入到内存中）中存储的直接数据块信息直接找到逻辑盘块对应的物理盘块号，读写速度很快。
  * （3）对于中等大小的文件，只要读入一阶索引块以后就能映射出物理盘块号，速度也不慢。
  * （4）通过多阶间接索引，可以映射尺寸很大的文件。而且即使文件尺寸很大，索引的阶数也不会很大，这是因为文件尺寸和索引阶数是一个指数关系，所以对于很大尺寸的文件存取也不太慢。
* 总的来说，多阶索引存储结构，无论是大文件、中文件还是小文件，无论是文件读还是文件写，其工作效率都较好。因此该方案对于通用操作系统而言是一个很好的折中方案
  * 很多实际操作系统，如 UNIX、Linux 都采用这种文件存储结构。



###  文件实现

文件抽象基本过程

* 给定一个文件inode；
* 给出一个字符流读写位置；
* 操作系统要通过 inode 中存放的索引信息找到文件读写位置所在的物理盘块号；
* 然后利用这个盘块号去调用 bread。



sys_write（例如：将 200 到 211 的字符改为 ...）

```c
int sys_write(int fd, const char* buf, int count)
{
    struct file *file = current->filp[fd];
    struct m_inode *inode = file->inode;
    // inode 对应的不是字符设备，而是常规文件，跳到 file_write(inode, file, buf,count) 去执行。
    if(S_ISREG(inode->i_mode))
    	return file_write(inode, file, buf, count);
}

int file_write(struct m_inode *inode, struct file *filp, char *buf, int count)
{
    off_t pos;
    // 首先找到文件读写对应的字符流位置，即给出的位置 200
    // 这里的读写位置 200 并不需要用户显式地告诉文件系统，而是通过文件读写指针隐式地告诉file_write。
    // 文件读写指针是文件的当前读写位置，更确切地说，是文件最近一次读写结束时停留的读写位置。
    // 这种隐式方法更符合人的习惯，操作系统会帮我们记住
    if(filp->f_flags & O_APPEND)
    	pos=inode->i_size;
    // 文件的读写位置记录在打开文件对应的 file 数据结构中，更确切的说，是记录在该数据结构中的字段 f_pos 中
    // 语句 pos = filp->f_pos 取出来的 pos 就是我们所说的“200”了。
    else pos=filp->f_pos;
    
    while(i<count)
    {
        // 根据 pos 和索引节点（inode）中的索引信息来计算物理盘块号。 
        // pos / BLOCK_SIZE 算出来的就是逻辑块号，用这个数值去查找 inode 中的直接数据块、一阶索引抑或是二阶索引。
        // 我们这里讨论的是 sys_write（写文件），写文件很有可能会导致要给文件增加物理盘块，当然也要跟着增加索引项，
        // 所以才有此处的函数 create_block。
        block = create_block(inode, pos/BLOCK_SIZE);
        
        // 一旦找到物理盘块号，我们可以利用物理盘块号去真正写磁盘了
        // 写磁盘实际上就是写高速缓存，bh = bread(inode->i_dev, block) 用来获得一个缓存块，
        // 不管要从物理磁盘读入（改写文件内容），还是获得一个空闲缓存块（追加文件内容），总之执行完成
        // bread(inode->i_dev, block) 后得到了一个高速缓存块 bh，并且从用户角度而言，操作 bh 等同于操作物理磁盘。
        bh = bread(inode->i_dev, block);
        
        // 实现用户缓存 buf 和内核磁盘高速缓存 bh-> b_data 之间的数据交换。
        // 在 char *p = c+bh->b_data 获得内核缓存指针以后，循环 while(c–>0) *(p++) = get_fs_byte(buf++) 
        // 实现数据交换，将用户缓存中的字符逐个写到磁盘高速缓存中。
        int c = pos%BLOCK_SIZE;
        char *p = c+bh->b_data;
        bh->b_dirt = 1;
        c = BLOCK_SIZE-c;
        pos += c;
        while(c-- >0) 
            *(p++) = get_fs_byte(buf++);
        
        // 在适当的时候，操作系统会将磁盘高速缓存中的这个磁盘写请求放到电梯队列中，等磁盘中断的时候才真正写磁盘，
        // 这就是著名磁盘延迟写。
        // 至于什么时候适当，需要设计相应的算法，此处不再赘述。当然也可以通过 sync 系统调用直接写出高速缓存。
        brelse(bh);
    }
    // 修改 f_pos，因为读写指针已经移动了，下一次文件访问时应该从新的字符流位置开始。
    filp->f_pos=pos;
}
```

* bmap（create_block 调用的这个）

```c
int bmap(m_inode *inode, int block, int create)
{
    // block<7 表示逻辑盘块号小于等于 6，说明 inode中的直接数据块就能映射出盘块号
    // 所以直接返回 return inode->i_zone[block]就是物理盘块号了
    if(block<7)
    {
        // 当然如果这个逻辑盘块没有映射到物理盘块，即发现!inode->i_zone[block] 时
        // 就调用 new_block(inode->i_dev) 从磁盘上申请一个空闲物理盘块。
        if(create && !inode->i_zone[block])
        {
            inode->i_zone[block] = new_block(inode->i_dev);
            inode->i_ctime = CURRENT_TIME;
            inode->i_dirt=1;
        }
        return inode->i_zone[block];
    }
    
    // block-=7 以后再判断 if(block<256) 属于：逻辑盘块号对应的物理盘块号存放在一阶间接索引中
    // 所以接下来需要会读入一阶索引块，bread(inode->i_dev,inode->i_zone[7]) 用来读入这个索引块，
    // 接下来需要在这个索引块中寻找和逻辑块相对应的物理盘块号，这只是一个简单的数组查找问题，此处无需继续论述。
    block-=7;
    if(block<256)
    {
        bh = bread(inode->i_dev,inode->i_zone[7]);
    ······
}
struct d_inode
{
    unsigned short i_mode;
    ······
    unsigned short i_zone[9];
}
```

