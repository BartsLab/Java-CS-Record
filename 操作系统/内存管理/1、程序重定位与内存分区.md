# 程序重定位

## 运行时重定位

在编译形成可执行程序时，用到的地址都是从 0 开始的相对地址，这个地址通常被称作**逻辑地址**，当程序被载入到物理内存中时，可能使用任意一段空闲物理内存

* 此时为保证程序的顺利执行，就需要进行**程序重定位**（Relocation），即**将程序中的逻辑地址对应到实际使用的物理内存地址**。





编译时重定位

* 如果选择编译时修改地址，那就是编译时重定位。
* 在编译产生可执行代码时，要将程序中出现的逻辑地址全部加上物理起始地址以后再写入可执行文件。
* 编译时重定位显然不能用于任务不断“启动 - 退出”的通用计算机系统。



载入时重定位

* 在程序载入时，根据载入的物理内存地址区域来修改程序中的逻辑地址。
* 载入时重定位还是不够灵活：程序一旦载入到物理内存以后，就不能在内存中移动了，因为如果程序代码从 1000 出挪动到 2000 处以后，已经修改过的指令“call 1040”显然就不好使了。



在进程的执行过程中，进程的换入换出是很有必要的

* 进程1 执行过程中出现了长时间的阻塞等待，这段时间内如果进程 1 一直占据内存，必然造成内存资源的浪费。为提高内存的使用效率，可以将长期阻塞的进程 1 换出到磁盘上。
* 过了一段时间，进程 1 又可以执行了，怎么办？需要再找一段空闲内存将进程 1 换入，进程在载入内存并开始执行以后，仍然需要在内存中移动，面对这样的情况，载入时重定位的方法不可以正常工作。



**运行时重定位**

* 即在指令执行时才将指令的逻辑地址翻译成物理地址
* 程序载入内存执行（即进程创建）时，寻找一段空闲内存区域将程序放入，并记录下这段内存区域的基地址。每执行一条指令，都先将指令中的逻辑地址加上基地址以后才放在地址总线上。

* 硬件 MMU 来快速完成这个地址计算
  * MMU 都会自动的将指令中取出的逻辑地址和这个寄存器中的基地址加和，形成物理地址后发到地址总线上，这个**从逻辑地址到物理地址的换算过程通常被称作为地址翻译**。



每个进程的重定位基地址都要存放在其PCB 中

* 系统中有多个进程，每个进程被载入到不同的物理内存区域中，相应地产生了多个基地址。MMU进行重定位的 CPU 寄存器只能有一个。进程切换时将其 PCB 中存放的基地址取出来赋给这个 CPU 寄存器
* 基地址对应了一段以该基地址为起始地址的内存空间，所以基地址寄存器切换实际上就是一段地址空间的切换
* 因此到了现在，进程切换的两个部分，即**指令执行序列**的切换（内核栈切换、用户栈切换、PC 指针切换等），和**地址空间**的切换（重定位基址寄存器 LDTR 的切换）。





## 分段后地址翻译

* 分段的目的是为了符合程序员的思维，代码段、数据段、堆栈段，可以解耦合



对于分段来说，逻辑地址实际上是段内偏移

* 对于指令“call 40”中的逻辑地址 40，首先找到段号信息（就是 CS），再由于代码段就是第 0 段，利用段表的信息检索出代码段的基地址是 180K。地址翻译最终要做的工作就是 180K+40，所以“call 40”实际执行的结果就是设置 PC = 180K+40，此时取出来的下一条指令正是“mov 1,[300]”，程序正确执行。

  ![在这里插入图片描述](https://img-blog.csdnimg.cn/20210121003951266.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzkzNDYwNw==,size_16,color_FFFFFF,t_70)


* 总的来说，分段机制下的地址翻译过程核心就是查找段表





段表

* 每个进程都有自己的段表，而 GDT 只有一个，所以每个进程的段表实际上是 LDT

* GDT 表描述的是操作系统的代码段、数据段等，LDT 表才用来描述每个进程在用户态的代码段、数据段等。

* 另外为了让操作系统找到每个进程的段信息，GDT 表中还有指向各个进程 LDT表的表项，所以 GDT 才是 Global 而 LDT 是 Local。

  ![在这里插入图片描述](https://img-blog.csdnimg.cn/20210121004012246.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzkzNDYwNw==,size_16,color_FFFFFF,t_70)






# 内存分区

* 即如果按段分配物理内存的问题，然后又提出物理上分页存储



## 分区算法与问题

* 即按段分配的算法与问题



核心是分割内存区域，

* 另外，由于请求放入内存的段尺寸不固定，分割的内存区域也不是固定大小的，所以该算法再具体一些被称为可变分区。

  ![在这里插入图片描述](https://img-blog.csdnimg.cn/20210121004026686.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzkzNDYwNw==,size_16,color_FFFFFF,t_70)




分区适配算法

* 操作系统中的进程不仅申请内存，在进程执行过程中也会释放内存

  * 例如：进程 2 结束退出时，进程 2: 段 1 的内存区域要释放，此时操作系统中就会出现两块空闲内存区域

* 这时候进入了一个长度为 40K 的段请求，两个空闲内存区域都能满足要求，应该选择哪一个？

  * 这就是分区适配算法要解决的问题

 ![在这里插入图片描述](https://img-blog.csdnimg.cn/20210121004041601.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzkzNDYwNw==,size_16,color_FFFFFF,t_70)


  

  


分区适配算法----最佳适配

* 分区的选择能够满足要求且最不浪费（即尺寸最小）的空闲区域，这种适配方法被称为最佳适配。
  * 最佳适配选择出来是大小为 50KB 的那个空闲区域。
* 最佳适配的适配算法在实际操作系统中并不是最好的：虽然此次申请产生的“浪费”最少，但实际上，这里所谓的“浪费”并不是真的浪费，因为分割剩下的空闲分区还可以再分配给其他内存请求。
  * 不难想象，最佳适配会让这些剩余空闲分区越来越小，将来分配给其他请求的可能性也就越来越小，不能分配给任何进程的空闲内存区域才是真正的浪费。



分区适配算法----最差适配

* 为了避免这种小空闲内存区域的出现，可采用和最佳适配刚好相反的思想，即每次选择满足请求大小且尺寸最大的空闲区域的最差适配算法。
  * 最差适配选择出来的是那个大小为 150KB 的空闲区域
* 那么最差适配会造成什么效果呢？显然会出现很多中等大小的空闲内存区域。



分区适配算法----最先适配

* 如果操作系统的内存请求没有规律，并且对于大小也没有规律，此时就没有必要专门采用最佳适配来制造出很大的空闲区域，也没有必要用最差适配来产生出很多中等大小的空闲区域。
* 可以用一个运算最快的算法来完成适配---最先适配，即在空闲内存区域表中找到第一个满足要求的分区即可，最先适配算法执行起来最快。
  * 最先适配选择出来的是大小为 150KB 的空闲区域 , 因为这个区域的记录在空闲分区表的最前面。





内存碎片问题

* 即虽然总的空闲内存很大，但是由一堆分散在物理内存多个位置的小区域组成，这些小区域由于不能满足进程的段尺寸要求而无法使用，从而造成空间浪费，这些小的空闲区域就被称为内存碎片。
* 操作系统要想高效地管理内存，就必须给出处理内存碎片的方案。处理内存碎片的直观方法是将空闲区域合并，即通过移动整理将很多零散的空闲区域合并成一整块空闲区域，这个过程被称为内存紧缩。
* 内存紧缩虽然可以解决内存碎片问题，但其缺点也是明显的：
  * 紧缩一遍内存需要花费一定时间，就算内存读写速度可以达到 10G/s，对一个 10G 大小的内存紧缩一遍需要的时间也超过 2s，内存紧缩的时候，操作系统中的所有进程不能执行任何动作



分页机制

* 内存离散化，即将内存分割成固定大小的小片。内存请求到达时，根据请求尺寸计算出总共需要的小片个数，然后在内存中（哪里都可以）找出同样数量的小片分配给内存请求。
  * 就前面的例子，现在有 150K 和 50K 两块空闲内存区域，内存请求的尺寸是 160K。如果要是能将内存请求打散，比如以 10K 为单位打散，那么 160K请求就是 16 片，150K 的空闲内存区域能满足 15 片请求，然后在 50K 空闲内存区域上分配 1 片，160K 的内存请求就能全部满足。内存碎片解决了。
* 分页机制的基本思想，这里的小片就是著名的内存页，因此，分页机制是解决内存碎片问题而提出的重要方法，可以有效提高内存的空间使用效率，所以通常的操作系统都支持分页机制。



## 分页及实现

* 解决按段分配导致的物理内存碎片问题



分页机制

* 分页机制首先将物理内存分割成大小相等的页框，然后再将请求放入物理内存的数据（比如代码段）也分割成同样大小的页，最后将所有页都载入到（映射到）页框上，完成物理内存页框的使用。 



重定位问题

* 例如在执行指令“mov [0x2240], %eax”时，我们到底要取出物理内存中哪个单元的内容赋给寄存器 EAX。我们假定页框大小为 4K（这是操作系统通常定义的页框大小），逻辑地址 0x2240 表示这个单元在进程段的第 2 个页面上。

* 根据**载入时建立的映射关系**，第 2 个页面被放到了第 3 个页框里，逻辑地址0x2240 对应了物理地址 0x3240。因此“mov [0x2240], %eax”是将物理内存单元 0x3240 处的内容取出来赋给寄存器 EAX。

  ![在这里插入图片描述](https://img-blog.csdnimg.cn/2021012100405888.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzkzNDYwNw==,size_16,color_FFFFFF,t_70)


页面尺寸

* 为了避免内存空间的浪费，页面尺寸应该设置的较小，通常的操作系统都将页面尺寸设置为 4K，相比现在动辄数 G 的程序、数据以及内存而言，4K 这个数字并不大。
* 如果页面尺寸较小，页表就会较大，这也是一个重要问题



两级页表

* 解决的问题

  * 每个进程都要有自己的页表，即从 GDT/LDT 查出来的是该段对应页表基地址，因为页表的表项个数必须是 内存大小/页面大小（原因是页表内必须连续，因为去找第几个页表项是通过虚拟地址（GDT/LDT 里 32 位的段基址 + EIP）的前 20 位直接获得，然后用这个基地址直接加上这个偏移找到对应的表项，然后获得物理页地址），那么假设 32 位系统 4G 内存的话，一个页面 4K ，那么每个就有 $2^{20}$ 个表项，每个表项 32 位，即一个进程的页表就要占 1M*4B = 4MB。如果有 100 个进程那么就要占 400 MB
  * 但是并不是每个进程会用到 32 位对应的全部内存，所以为了高效（即查页表高效，如果页表里面不连续就要用二分查找去查多次）会牺牲很多内存，因此有了两级页表，每一级的页表内部都是连续的

* 两级页表的基本结构是引入页目录项，一个页目录项下面会包含多个页号连续的页表项，页表项映射了一页内存，而页目录项映射了一块内存

  ![在这里插入图片描述](https://img-blog.csdnimg.cn/20210121004112465.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzkzNDYwNw==,size_16,color_FFFFFF,t_70)


  


快表 TLB

* 多级页表引入页目录以后虽然可以降低存储页表造成的空间代价，但页目录的引入也让地址翻译时间变长 

  * 如果只有页表，只查找一次页表就能完成地址翻译，而现在需要先查找一次页目录表，然后才能查找页表，所以需要查表两次，地址翻译的时间效率降低了 50%。
  * 如果是 4 级页表，地址翻译的时间效率会变为单级页表的 1/4。

* 快表，英文名称为 TLB（Translation Lookaside Buffer），即硬件设计出一种电路让整个缓存页表的查找一次完成

  * TLB 中会缓存那些常用的逻辑页映射关系，此时的地址翻译过程就是：先查 TLB，如果击中，很快能获得物理页框号；如果没有击中，则查找页目录表、查找页表，找到物理页框号并更新 TLB
  * TLB 中会存放现在常用的逻辑页，而程序局部性规律又说明最近使用的逻辑页通常都是现在常用的，再由于 TLB 的查找速度非常快，所以引入快表以后的多级页表结构会让地址翻译速度变得很快。

  ![在这里插入图片描述](https://img-blog.csdnimg.cn/2021012100412864.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzkzNDYwNw==,size_16,color_FFFFFF,t_70)


  

分页的完整故事

  * （1）将物理内存分成页并以页为单位进行内存分配，可以解决内存碎片问题造成的空间浪费；
  * （2）一旦分页以后，需要存放页表来完成地址翻译过程；
  * （3）采用多级页表可以降低存放页表造成的空间开销；
  * （4）采用快表（TLB）来降低多级页表造成的时间开销；
  * （5）最终形成的是综合多级页表和快表的分页机制，时间开销和空间开销上都表现良好，很多实际操作系统都支持快表和多级页表，比如操作系统实例Linux 0.11。

  
