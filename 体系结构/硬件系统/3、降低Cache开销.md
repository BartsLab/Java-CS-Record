### 减少Cache不命中开销

#### 增加二级Cahche

采用两级Cache

* 应把Cache做得更快? 还是更大?
  * 二者兼顾，再增加一级Cache
    * 第一级Cache(L1)小而快
    * 第二级Cache (L2)容量大
* 性能分析
  * 平均访存时间 = 命中时间L1＋(不命中率y1 × 不命中开销)
  * 不命中开销L1 = 命中时间L2+ (不命中率L2 × 不命中开销L2)
  * 平均访存时间 = 命中时间L1 + {不命中率L1 × [命中时间L2＋(不命中率l2×不命中开销L2)]}



局部不命中率与全局不命中率

* 局部不命中率 = 该级Cache的不命中次数 / 到达该级Cache的访问次数
* 全局不命中率 = 该级Cache的不命中次数 / CPU发出的访存的总次数
* 全局不命中率L2 = 不命中率L1 × 不命中率L2
* 评价第二级Cache时，应使用全局不命中率这个指标。它指出了在CPU发出的访存中，究竟有多大比例是穿过各级Cache,最终到达存储器的。



二级 cache 

* 在第二级Cache比第一级Cache大得多的情况下，两级Cache的全局不命中率和容量与第二级Cache相同的单级Cache的不命中率非常接近。

* 第二级Cache不会影响CPU的时钟频率，因此其设计有更大的考虑空间。

  * 两个问题需要权衡：
    * 它能否降低CPI中的平均访存时间部分
    * 它的成本是多少

* 第二级Cache的参数

  * 容量
    * 第二级Cache的容量一般比第一级的大许多。
    * 大容量意味着第二级Cache可能实际上没有容量不命中，只剩下一些强制性不命中和冲突不命中
  * 相联度
    * 第二级Cache可采用较高的相联度或伪相联方法。
  * 块大小
    * 第二级Cache可采用较大的块，如 64、128、256字节
    * 为减少平均访存时间，可以让容量较小的第一级Cache采用较小的块，而让容量较大的第二级Cache采用较大的块。
    * 多级包容性，需要考虑的另一个问题：第一级Cache中的数据是否总是同时存在于第二级Cache中。





#### 其他三种策略

优化策略一：查找与优化写缓冲

* 写缓冲的目的

  * 因为 cache 之间有一致性协议，所以每次写 cache 都会在 cache 之间进行通信，所以就会浪费时钟周期，无法接着执行下条指令
  * 加入写缓冲后，cpu 每次把结果先写到写缓冲，而不是 cache 中，这样就可以接着立即执行下条指令

* Cache中的写缓冲器导致对存储器访问的复杂化

  * 导致的问题
    * 在读不命中时，所读单元的最新值有可能还在写缓冲器中，尚未写入主存。
  * 解决问题的方法(读不命中的处理) 
  * 推迟对读不命中的处理，直到写缓冲器清空。（缺点:读不命中的开销增加）
    * 检查写缓冲器中的内容（让读不命中优先于写）
  * 在写回法Cache中，也可采用写缓冲器。

    * 依靠写缓冲来减少对下一级存储器写操作的时间。

* 写缓冲优化策略：写缓冲合并

  * 如果写缓冲器为空，就把数据和相应地址写入该缓冲器。从CPU的角度来看，该写操作就算是完成了。

  * 如果写缓冲器中已经有了待写入的数据，就要把这次的写入地址与写缓冲器中已有的所有地址进行比较，看是否有匹配的项。如果有地址匹配而对应的位置又空闲，就把这次要写入的数据与该项合并。这就叫写缓冲合并。

  * 如果写缓冲器满且又没有能进行写合并的项，就必须等待。

  * 效果：提高了写缓冲器的空间利用率，而且还能减少因写缓冲器满而要进行的等待时间。

    <img src="https://img-blog.csdnimg.cn/20201225155932580.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzkzNDYwNw==,size_16,color_FFFFFF,t_70" width="67%" />







优化策略二：请求字处理技术

* 请求字
  * 从下一级存储器调入Cache的块中，只有一个字是立即需要的。这个字称为请求字。
* 应尽早把请求字发送给CPU
  * 尽早重启动：调块时，从块的起始位置开始读起。一旦请求字到达，就立即发送给CPU，让CPU继续执行。
  * 请求字优先：调块时，从请求字所在的位置读起这样，第一个读出的字便是请求字。将之立即发送给CPU。

* 这种技术在以下情况下效果不大
  * Cache块较小
  * 下一条指令正好访问同一Cache块的另一部分



优化策略三：非阻塞Cache技术

* 非阻塞Cache: 
  * Cache不命中时仍允许CPU进行其它的命中访问。即允许“不命中下命中”
* 进一步提高性能 (存储器必须能够处理多个不命中) :
  * “多重不命中下命中”
  * “不命中下不命中”

* 可以同时处理的不命中次数越多，所能带来的性能上的提高就越大。


### 减少Cache命中时间

#### 概述

重要性

* 命中时间直接影响到处理器的时钟频率。
* 在当今的许多计算机中，往往是Cache的访问时间限制了处理器的时钟频率。



#### 五种策略

优化策略一：使用容量小、结构简单的Cache

* 硬件越简单，速度就越快;

* 应使Cache足够小,以便可以与CPU一起放在同一块芯片上。

* 把Cache的标识放在片内，而把Cache的数据存储器放在片外。





优化策略二：虚拟Cache

* 物理Cache

  * 使用物理地址进行访问的传统Cache。

  * 标识存储器中存放的是物理地址，进行地址检测也是用物理地址。

  * 缺点：

    * 地址转换和访问Cache串行进行，访问速度很慢。

    <img src="https://img-blog.csdnimg.cn/2020122516013780.png" width="45%" />

* 虚拟Cache

  * 可以直接用虚拟地址进行访问的Cache。标识存储器中存放的是虚拟地址，进行地址检测用的也是虚拟地址。

  * 优点：

    * 在命中时不需要地址转换，省去了地址转换的时间。、
    * 即使不命中，地址转换和访问Cache也是并行进行的，其速度比物理Cache快很多。

    <img src="https://img-blog.csdnimg.cn/2020122516004145.png" width="45%" />

  * 并非都采用虚拟Cache

    * 虚拟Cache的清空问题（虚拟地址是跟进程相关的）

      * 解决方法：在地址标识中增加PID字段(进程标识符)
      * 三种情况下不命中率的比较：
        * 单进程，PIDs，清空
        * PIDs与单进程相比：+0.3%～+0.6%
        * PIDs与清空相比：—0.6%～—4.3%

    * 同义和别名：对同一物理地址采用多种不同形式的虚拟地址。




优化策略三：虚拟索引＋物理标识

* 用虚地址中页内位移作为Cache的索引，标识用物理地址;

  <img src="https://img-blog.csdnimg.cn/20201225160107770.png" width="45%"/>

* 优点:

  * 兼得虚拟Cache和物理Cache的好处

* 局限性

  * Cache容量受到限制 (页内位移)
  * Cache容量 ≤ 页大小×相联度

* 举例：IBM3033的Cache

  * 页大小=4KB，相联度=16
  * Cache容量=16×4KB=64KB



优化策略四：Cache访问流水化

* 对第一级Cache的访问按流水方式组织
* 访问Cache需要多个时钟周期才可以完成
  * Pentium访问指令Cache需要一个时钟周期
  * Pentium Pro到PentiumⅢ需要两个时钟周期
  * Pentium 4则需要4个时钟周期
* 不能够真正减少Cache命中时间，但是可以提高时钟频率，提高Cache的带宽。



优化策略五：踪迹Cache

* 开发指令级并行性所遇到的一个挑战是:
  * 当要每个时钟周期流出超过4条指令时，要提供足够多条彼此互不相关的指令是很困难的。
* 一个解决方法：采用踪迹Cache
  * 存放CPU所执行的动态指令序列包含了由分支预测展开的指令，该分支预测是否正确需要在取到该指令时进行确认。
* 优缺点
  * 地址映象机制复杂
  * 相同的指令序列有可能被当作条件分支的不同选择而重复存放
  * 能够提高指令Cache的空间利用率。

